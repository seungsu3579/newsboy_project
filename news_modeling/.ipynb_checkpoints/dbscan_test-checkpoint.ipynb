{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unique-attendance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting appnope==0.1.2\n",
      "  Downloading appnope-0.1.2-py2.py3-none-any.whl (4.3 kB)\n",
      "Requirement already satisfied: argon2-cffi==20.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (20.1.0)\n",
      "Requirement already satisfied: async-generator==1.10 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.10)\n",
      "Requirement already satisfied: attrs==20.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (20.3.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0)\n",
      "Requirement already satisfied: bleach==3.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (2020.12.5)\n",
      "Collecting cffi==1.14.5\n",
      "  Downloading cffi-1.14.5-cp38-cp38-manylinux1_x86_64.whl (411 kB)\n",
      "\u001b[K     |████████████████████████████████| 411 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (4.0.0)\n",
      "Requirement already satisfied: colorama==0.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.4.4)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml==0.6.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (0.3)\n",
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (2.10)\n",
      "Collecting importlib-metadata==3.7.0\n",
      "  Downloading importlib_metadata-3.7.0-py3-none-any.whl (11 kB)\n",
      "Collecting ipykernel==5.5.0\n",
      "  Downloading ipykernel-5.5.0-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython==7.21.0\n",
      "  Downloading ipython-7.21.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (0.2.0)\n",
      "Requirement already satisfied: jedi==0.18.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (0.18.0)\n",
      "Requirement already satisfied: Jinja2==2.11.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (2.11.3)\n",
      "Collecting joblib==1.0.1\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: JPype1==1.2.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 24)) (1.2.1)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 25)) (3.2.0)\n",
      "Requirement already satisfied: jupyter-client==6.1.11 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 26)) (6.1.11)\n",
      "Requirement already satisfied: jupyter-core==4.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 27)) (4.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments==0.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (0.1.2)\n",
      "Requirement already satisfied: konlpy==0.5.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (0.5.2)\n",
      "Requirement already satisfied: lxml==4.6.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 30)) (4.6.2)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 31)) (1.1.1)\n",
      "Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 32)) (0.8.4)\n",
      "Collecting nbclient==0.5.3\n",
      "  Downloading nbclient-0.5.3-py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbconvert==6.0.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (6.0.7)\n",
      "Requirement already satisfied: nbformat==5.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (5.1.2)\n",
      "Requirement already satisfied: nest-asyncio==1.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 36)) (1.5.1)\n",
      "Requirement already satisfied: notebook==6.2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 37)) (6.2.0)\n",
      "Collecting numpy==1.20.1\n",
      "  Downloading numpy-1.20.1-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.4 MB 9.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 39)) (3.1.0)\n",
      "Requirement already satisfied: packaging==20.9 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 40)) (20.9)\n",
      "Collecting pandas==1.2.2\n",
      "  Downloading pandas-1.2.2-cp38-cp38-manylinux1_x86_64.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 9.0 MB/s eta 0:00:01     |██████████████████▋             | 5.6 MB 9.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandocfilters==1.4.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 42)) (1.4.3)\n",
      "Requirement already satisfied: parso==0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 43)) (0.8.1)\n",
      "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 44)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 45)) (0.7.5)\n",
      "Requirement already satisfied: prometheus-client==0.9.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 46)) (0.9.0)\n",
      "Collecting prompt-toolkit==3.0.16\n",
      "  Downloading prompt_toolkit-3.0.16-py3-none-any.whl (366 kB)\n",
      "\u001b[K     |████████████████████████████████| 366 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psycopg2-binary==2.8.6\n",
      "  Downloading psycopg2_binary-2.8.6-cp38-cp38-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 49)) (0.7.0)\n",
      "Requirement already satisfied: pycparser==2.20 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 50)) (2.20)\n",
      "Collecting Pygments==2.8.0\n",
      "  Downloading Pygments-2.8.0-py3-none-any.whl (983 kB)\n",
      "\u001b[K     |████████████████████████████████| 983 kB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 52)) (2.4.7)\n",
      "Requirement already satisfied: pyrsistent==0.17.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 53)) (0.17.3)\n",
      "Requirement already satisfied: PySocks==1.7.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 54)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 55)) (2.8.1)\n",
      "Collecting pytz==2021.1\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyzmq==22.0.3\n",
      "  Downloading pyzmq-22.0.3-cp38-cp38-manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 58)) (2.25.1)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 59)) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.24.1\n",
      "  Downloading scikit_learn-0.24.1-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 8.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.6.1\n",
      "  Downloading scipy-1.6.1-cp38-cp38-manylinux1_x86_64.whl (27.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.3 MB 10.5 MB/s eta 0:00:01    |██████████▏                     | 8.7 MB 12.9 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 62)) (1.5.0)\n",
      "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 63)) (1.15.0)\n",
      "Collecting sklearn==0.0\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting smart-open==4.2.0\n",
      "  Downloading smart_open-4.2.0.tar.gz (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: terminado==0.9.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 66)) (0.9.2)\n",
      "Requirement already satisfied: testpath==0.4.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 67)) (0.4.4)\n",
      "Collecting threadpoolctl==2.1.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tornado==6.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 69)) (6.1)\n",
      "Collecting tqdm==4.58.0\n",
      "  Downloading tqdm-4.58.0-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 1.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets==5.0.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 71)) (5.0.5)\n",
      "Requirement already satisfied: tweepy==3.10.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 72)) (3.10.0)\n",
      "Collecting typing-extensions==3.7.4.3\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: urllib3==1.26.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 74)) (1.26.3)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 75)) (0.2.5)\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 76)) (0.5.1)\n",
      "Collecting zipp==3.4.0\n",
      "  Downloading zipp-3.4.0-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython==7.21.0->-r requirements.txt (line 19)) (45.2.0)\n",
      "Building wheels for collected packages: sklearn, smart-open\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=1ae9350798d2ad9d1fe76dfc407a9d387bd3e4e4a7c9146ccc0278bac4b47566\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-4.2.0-py3-none-any.whl size=109629 sha256=88c63c11c9b3b606f5424c2a4ee82d360533e0be496b412ef92cf03ae3ca3014\n",
      "  Stored in directory: /root/.cache/pip/wheels/24/f6/ea/70a0761bdfaeacff66662751fe71920e25c4c43d97098a3886\n",
      "Successfully built sklearn smart-open\n",
      "Installing collected packages: pyzmq, Pygments, prompt-toolkit, numpy, threadpoolctl, scipy, nbclient, joblib, ipython, cffi, zipp, smart-open, scikit-learn, pytz, ipykernel, typing-extensions, tqdm, sklearn, psycopg2-binary, pandas, importlib-metadata, gensim, appnope\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 22.0.2\n",
      "    Uninstalling pyzmq-22.0.2:\n",
      "      Successfully uninstalled pyzmq-22.0.2\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.7.4\n",
      "    Uninstalling Pygments-2.7.4:\n",
      "      Successfully uninstalled Pygments-2.7.4\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.14\n",
      "    Uninstalling prompt-toolkit-3.0.14:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.14\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.0\n",
      "    Uninstalling numpy-1.20.0:\n",
      "      Successfully uninstalled numpy-1.20.0\n",
      "  Attempting uninstall: nbclient\n",
      "    Found existing installation: nbclient 0.5.1\n",
      "    Uninstalling nbclient-0.5.1:\n",
      "      Successfully uninstalled nbclient-0.5.1\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.20.0\n",
      "    Uninstalling ipython-7.20.0:\n",
      "      Successfully uninstalled ipython-7.20.0\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.4\n",
      "    Uninstalling cffi-1.14.4:\n",
      "      Successfully uninstalled cffi-1.14.4\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 5.4.3\n",
      "    Uninstalling ipykernel-5.4.3:\n",
      "      Successfully uninstalled ipykernel-5.4.3\n",
      "Successfully installed Pygments-2.8.0 appnope-0.1.2 cffi-1.14.5 gensim-3.8.3 importlib-metadata-3.7.0 ipykernel-5.5.0 ipython-7.21.0 joblib-1.0.1 nbclient-0.5.3 numpy-1.20.1 pandas-1.2.2 prompt-toolkit-3.0.16 psycopg2-binary-2.8.6 pytz-2021.1 pyzmq-22.0.3 scikit-learn-0.24.1 scipy-1.6.1 sklearn-0.0 smart-open-4.2.0 threadpoolctl-2.1.0 tqdm-4.58.0 typing-extensions-3.7.4.3 zipp-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-mortality",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'word2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b29b8c80548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordToVector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordToVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'word2vec'"
     ]
    }
   ],
   "source": [
    "from word2vec.model import WordToVector\n",
    "\n",
    "wv = WordToVector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.controller import DBController\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ideal-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = datetime.datetime.strptime('2020-01-01 19:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "interval = datetime.timedelta(hours=1)\n",
    "\n",
    "db = DBController()\n",
    "\n",
    "rows = db.get_keywords_by_time(a, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "checked-empire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broke-uniform",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-806322dc1e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkeywords_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize_word_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w2v' is not defined"
     ]
    }
   ],
   "source": [
    "data = list()\n",
    "for row in rows:\n",
    "    temp = dict()\n",
    "    keywords_list = row['keywords'].lstrip(\"{\").rstrip(\"}\").split(\",\")\n",
    "    vector = w2v.vectorize_word_list(keywords_list)\n",
    "    \n",
    "    if (type(vector) != numpy.ndarray): continue\n",
    "        \n",
    "    temp[\"id\"] = row['id']\n",
    "    temp[\"keywords\"] = row[\"keywords\"]\n",
    "    temp[\"headline\"] = row['article_headline']\n",
    "    for col, element in enumerate(vector):\n",
    "        temp[str(col)] = element\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-brick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "banner-strip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "worth-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "polyphonic-feelings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keywords', 'headline', '0', '1', '2', '3', '4', '5', '6', '7',\n",
       "       ...\n",
       "       '290', '291', '292', '293', '294', '295', '296', '297', '298', '299'],\n",
       "      dtype='object', length=302)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df = df.set_index(\"id\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "constant-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[str(i) for i in range(300)]] \n",
    "# X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "headed-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.15, min_samples=2, metric='cosine').fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aboriginal-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1, 2, 3}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "systematic-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "elect-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 4\n",
      "Estimated number of noise points: 57\n"
     ]
    }
   ],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "collective-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_ = n_clusters_\n",
    "for index, cluster in enumerate(labels):\n",
    "    if cluster == -1:\n",
    "        labels[index] = tmp_\n",
    "        tmp_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "widespread-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-1cf3959d929a>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results[\"clusters\"] = labels\n"
     ]
    }
   ],
   "source": [
    "results = df[[\"headline\", \"keywords\"]]\n",
    "results[\"clusters\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "straight-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=\"clusters\").to_csv(\"./dbscan_results_0.15_2020-11-15.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "agricultural-article",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11010180004785704</th>\n",
       "      <td>이번주 유가 동향국내 휘발윳값 12주째 하락…1318.3원</td>\n",
       "      <td>{가격,주유소,평균,휘발유,판매,전국,전주,경유}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010180004785703</th>\n",
       "      <td>연말 증시 전략…코로나19가 변수</td>\n",
       "      <td>{봉쇄,확산,코로나,증시,연구원,경기,회복,미국}</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010110003825832</th>\n",
       "      <td>“내년이 더 문제”고소득자 신용대출 규제에 은행권 우려한 까닭은</td>\n",
       "      <td>{대출,차주,신용,은행,부채,적용,상환}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010180004785702</th>\n",
       "      <td>GCF 기후변화 대응 20.8억달러 규모 사업 신규 추진</td>\n",
       "      <td>{기후,사업,달러,변화,사회,계획,지원,온실가스}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11014210004989671</th>\n",
       "      <td>조은산 윤희숙 홍남기 말해달라…주52시간제 되면 내 월급 그대로인지</td>\n",
       "      <td>{전태일,의원,자신,정신,부총리,노동자,시간}</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010880000671843</th>\n",
       "      <td>알쏭달쏭 생활법률 가계약금을 받은 매도인의 계약해제</td>\n",
       "      <td>{계약금,지급,계약,해제,배액,경우,상환}</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11012770004791775</th>\n",
       "      <td>여전한 코로나發 고용절벽…실업률 21년만에 최고치</td>\n",
       "      <td>{고용,개월,연속,실업자,취업자,이후}</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11012770004791789</th>\n",
       "      <td>망치로 때리는 듯한 고통…바이든이 두차례 수술받은 병은</td>\n",
       "      <td>{뇌동맥류,당선인,파열,정도,바이든,수술}</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010010012014096</th>\n",
       "      <td>트럼프 바이든 취임전 알래스카보호구역 석유시추권 경매</td>\n",
       "      <td>{시추,경매,바이든,취임,절차,석유,블룸버그,시작,야생,행정부}</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11010180004785694</th>\n",
       "      <td>부알못 탈출기전월세 계약시 특약사항도 꼼꼼하게</td>\n",
       "      <td>{특약,임차인,사항,계약,임대인,금지,부담}</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  \\\n",
       "id                                                         \n",
       "11010180004785704       이번주 유가 동향국내 휘발윳값 12주째 하락…1318.3원   \n",
       "11010180004785703                     연말 증시 전략…코로나19가 변수   \n",
       "11010110003825832    “내년이 더 문제”고소득자 신용대출 규제에 은행권 우려한 까닭은   \n",
       "11010180004785702        GCF 기후변화 대응 20.8억달러 규모 사업 신규 추진   \n",
       "11014210004989671  조은산 윤희숙 홍남기 말해달라…주52시간제 되면 내 월급 그대로인지   \n",
       "...                                                  ...   \n",
       "11010880000671843           알쏭달쏭 생활법률 가계약금을 받은 매도인의 계약해제   \n",
       "11012770004791775            여전한 코로나發 고용절벽…실업률 21년만에 최고치   \n",
       "11012770004791789         망치로 때리는 듯한 고통…바이든이 두차례 수술받은 병은   \n",
       "11010010012014096          트럼프 바이든 취임전 알래스카보호구역 석유시추권 경매   \n",
       "11010180004785694              부알못 탈출기전월세 계약시 특약사항도 꼼꼼하게   \n",
       "\n",
       "                                              keywords  clusters  \n",
       "id                                                                \n",
       "11010180004785704          {가격,주유소,평균,휘발유,판매,전국,전주,경유}         4  \n",
       "11010180004785703          {봉쇄,확산,코로나,증시,연구원,경기,회복,미국}         5  \n",
       "11010110003825832               {대출,차주,신용,은행,부채,적용,상환}         0  \n",
       "11010180004785702          {기후,사업,달러,변화,사회,계획,지원,온실가스}         1  \n",
       "11014210004989671            {전태일,의원,자신,정신,부총리,노동자,시간}         6  \n",
       "...                                                ...       ...  \n",
       "11010880000671843              {계약금,지급,계약,해제,배액,경우,상환}        56  \n",
       "11012770004791775                {고용,개월,연속,실업자,취업자,이후}        57  \n",
       "11012770004791789              {뇌동맥류,당선인,파열,정도,바이든,수술}        58  \n",
       "11010010012014096  {시추,경매,바이든,취임,절차,석유,블룸버그,시작,야생,행정부}        59  \n",
       "11010180004785694             {특약,임차인,사항,계약,임대인,금지,부담}        60  \n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-state",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
